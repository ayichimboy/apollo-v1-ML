{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19afec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  data_scientist                 task project_type complexity_level  \\\n",
      "0         Hannah  Feature_Engineering          NLP           Medium   \n",
      "1          Diana       Data_Wrangling          NLP             High   \n",
      "2         George       Data_Wrangling      Tabular             High   \n",
      "3          Alice        Data_Cleaning       Vision             High   \n",
      "4         Fatima     Model_Monitoring  Time Series             High   \n",
      "5          Diana       Model_Building       Vision             High   \n",
      "6         George       Model_Building          NLP             High   \n",
      "7        Charlie        Data_Cleaning  Time Series           Medium   \n",
      "8         Fatima       Data_Wrangling          NLP             High   \n",
      "9         George     Model_Deployment  Time Series             High   \n",
      "\n",
      "      tool_used  data_size_gb  deadline_days  time_hours  \n",
      "0       PyTorch      3.807947             19       10.21  \n",
      "1    TensorFlow      1.644585             23       10.51  \n",
      "2    TensorFlow      1.089752             15        7.01  \n",
      "3       XGBoost      7.109919             26        9.28  \n",
      "4  Scikit-learn      0.658475             28        3.94  \n",
      "5    TensorFlow      1.900067             25       15.56  \n",
      "6    TensorFlow      6.213067             26        7.19  \n",
      "7  Scikit-learn      0.561990             20        4.99  \n",
      "8       XGBoost      2.404436             19        5.76  \n",
      "9       XGBoost      9.833986             29        8.88  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Define categories\n",
    "# -----------------------------\n",
    "data_scientists = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Ethan\", \"Fatima\", \"George\", \"Hannah\"]\n",
    "tasks = [\n",
    "    \"Data_Cleaning\",\n",
    "    \"Data_Wrangling\",\n",
    "    \"Exploratory_Analysis\",\n",
    "    \"Feature_Engineering\",\n",
    "    \"Model_Building\",\n",
    "    \"Model_Testing\",\n",
    "    \"Model_Deployment\",\n",
    "    \"Model_Monitoring\"\n",
    "]\n",
    "project_types = [\"NLP\", \"Vision\", \"Tabular\", \"Time Series\"]\n",
    "complexity_levels = [\"Low\", \"Medium\", \"High\"]\n",
    "tools = [\"Scikit-learn\", \"PyTorch\", \"TensorFlow\", \"XGBoost\", \"LightGBM\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Set average times per task (base times in hours)\n",
    "# -----------------------------\n",
    "avg_time = {\n",
    "    \"Data_Cleaning\": 4,\n",
    "    \"Data_Wrangling\": 5,\n",
    "    \"Exploratory_Analysis\": 6,\n",
    "    \"Feature_Engineering\": 7,\n",
    "    \"Model_Building\": 8,\n",
    "    \"Model_Testing\": 6,\n",
    "    \"Model_Deployment\": 4,\n",
    "    \"Model_Monitoring\": 3\n",
    "}\n",
    "\n",
    "# Complexity scaling factors\n",
    "complexity_factor = {\"Low\": 0.8, \"Medium\": 1.0, \"High\": 1.3}\n",
    "\n",
    "# Project type scaling (vision & NLP often take longer)\n",
    "project_factor = {\"Tabular\": 1.0, \"NLP\": 1.2, \"Vision\": 1.3, \"Time Series\": 1.1}\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Generate the synthetic dataset\n",
    "# -----------------------------\n",
    "np.random.seed(42)\n",
    "rows = []\n",
    "\n",
    "for _ in range(300):\n",
    "    name = random.choice(data_scientists)\n",
    "    task = random.choice(tasks)\n",
    "    project = random.choice(project_types)\n",
    "    complexity = random.choice(complexity_levels)\n",
    "    tool = random.choice(tools)\n",
    "    data_size = np.random.uniform(0.1, 10.0)  # GB\n",
    "    deadline = np.random.randint(5, 30)  # days\n",
    "    \n",
    "    # Calculate base time with modifiers\n",
    "    time = (\n",
    "        avg_time[task]\n",
    "        * complexity_factor[complexity]\n",
    "        * project_factor[project]\n",
    "        * (1 + data_size / 50)  # slightly scale with data size\n",
    "    )\n",
    "    \n",
    "    # Add noise (Â±20%)\n",
    "    time += np.random.normal(0, 0.2 * time)\n",
    "    time = round(max(0.5, time), 2)\n",
    "    \n",
    "    rows.append([name, task, project, complexity, tool, data_size, deadline, time])\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create DataFrame\n",
    "# -----------------------------\n",
    "df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"data_scientist\",\n",
    "        \"task\",\n",
    "        \"project_type\",\n",
    "        \"complexity_level\",\n",
    "        \"tool_used\",\n",
    "        \"data_size_gb\",\n",
    "        \"deadline_days\",\n",
    "        \"time_hours\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Save or preview\n",
    "# -----------------------------\n",
    "print(df.head(10))\n",
    "df.to_csv(\"data_science_productivity_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec67a686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   data_scientist    300 non-null    object \n",
      " 1   task              300 non-null    object \n",
      " 2   project_type      300 non-null    object \n",
      " 3   complexity_level  300 non-null    object \n",
      " 4   tool_used         300 non-null    object \n",
      " 5   data_size_gb      300 non-null    float64\n",
      " 6   deadline_days     300 non-null    int64  \n",
      " 7   time_hours        300 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_science_productivity_dataset.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed968e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "data_scientist",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "task",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "project_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "complexity_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tool_used",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_size_gb",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deadline_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_hours",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "15d7cf24-b8ab-48b7-990c-2d05cee00333",
       "rows": [
        [
         "0",
         "Hannah",
         "Feature_Engineering",
         "NLP",
         "Medium",
         "PyTorch",
         "3.807947176588889",
         "19",
         "10.21"
        ],
        [
         "1",
         "Diana",
         "Data_Wrangling",
         "NLP",
         "High",
         "TensorFlow",
         "1.6445845403801216",
         "23",
         "10.51"
        ],
        [
         "2",
         "George",
         "Data_Wrangling",
         "Tabular",
         "High",
         "TensorFlow",
         "1.0897516665982283",
         "15",
         "7.01"
        ],
        [
         "3",
         "Alice",
         "Data_Cleaning",
         "Vision",
         "High",
         "XGBoost",
         "7.10991852018085",
         "26",
         "9.28"
        ],
        [
         "4",
         "Fatima",
         "Model_Monitoring",
         "Time Series",
         "High",
         "Scikit-learn",
         "0.6584746323682925",
         "28",
         "3.94"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_scientist</th>\n",
       "      <th>task</th>\n",
       "      <th>project_type</th>\n",
       "      <th>complexity_level</th>\n",
       "      <th>tool_used</th>\n",
       "      <th>data_size_gb</th>\n",
       "      <th>deadline_days</th>\n",
       "      <th>time_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>Feature_Engineering</td>\n",
       "      <td>NLP</td>\n",
       "      <td>Medium</td>\n",
       "      <td>PyTorch</td>\n",
       "      <td>3.807947</td>\n",
       "      <td>19</td>\n",
       "      <td>10.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diana</td>\n",
       "      <td>Data_Wrangling</td>\n",
       "      <td>NLP</td>\n",
       "      <td>High</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>1.644585</td>\n",
       "      <td>23</td>\n",
       "      <td>10.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George</td>\n",
       "      <td>Data_Wrangling</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>High</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>1.089752</td>\n",
       "      <td>15</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Data_Cleaning</td>\n",
       "      <td>Vision</td>\n",
       "      <td>High</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7.109919</td>\n",
       "      <td>26</td>\n",
       "      <td>9.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fatima</td>\n",
       "      <td>Model_Monitoring</td>\n",
       "      <td>Time Series</td>\n",
       "      <td>High</td>\n",
       "      <td>Scikit-learn</td>\n",
       "      <td>0.658475</td>\n",
       "      <td>28</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_scientist                 task project_type complexity_level  \\\n",
       "0         Hannah  Feature_Engineering          NLP           Medium   \n",
       "1          Diana       Data_Wrangling          NLP             High   \n",
       "2         George       Data_Wrangling      Tabular             High   \n",
       "3          Alice        Data_Cleaning       Vision             High   \n",
       "4         Fatima     Model_Monitoring  Time Series             High   \n",
       "\n",
       "      tool_used  data_size_gb  deadline_days  time_hours  \n",
       "0       PyTorch      3.807947             19       10.21  \n",
       "1    TensorFlow      1.644585             23       10.51  \n",
       "2    TensorFlow      1.089752             15        7.01  \n",
       "3       XGBoost      7.109919             26        9.28  \n",
       "4  Scikit-learn      0.658475             28        3.94  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
